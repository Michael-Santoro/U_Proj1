{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TrainingRun.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "mount_file_id": "1Cwkaa7fzYfeMr-Iby0VuwtMPp4svTbKf",
      "authorship_tag": "ABX9TyMAh6bZPXDmSuC/GxBOSI2w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Michael-Santoro/U_Proj1/blob/main/TrainingRun.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check GPU Notebook"
      ],
      "metadata": {
        "id": "oLb2wKmTlVBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kSjmbDZMc5n",
        "outputId": "97f783fb-2492-40da-8a4f-0890b051256d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Object Detection"
      ],
      "metadata": {
        "id": "lGetjb7Llr-j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oi28cqGGFWnY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04f96296-aae1-469e-f771-b876d4468459"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 3390, done.\u001b[K\n",
            "remote: Counting objects: 100% (3390/3390), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2814/2814), done.\u001b[K\n",
            "remote: Total 3390 (delta 895), reused 1398 (delta 521), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (3390/3390), 34.93 MiB | 13.75 MiB/s, done.\n",
            "Resolving deltas: 100% (895/895), done.\n"
          ]
        }
      ],
      "source": [
        "# Clone the tensorflow models repository\n",
        "!git clone --depth 1 https://github.com/tensorflow/models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NwdsBdGhFanc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "805c6ddf-1938-42e0-81bb-903c53056399"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "protobuf-compiler is already the newest version (3.0.0-9.1ubuntu1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/models/research\n",
            "Collecting avro-python3\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "Collecting apache-beam\n",
            "  Downloading apache_beam-2.39.0-cp37-cp37m-manylinux2010_x86_64.whl (10.3 MB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.30)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n",
            "Collecting tf-slim\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.4)\n",
            "Collecting lvis\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.3.5)\n",
            "Collecting tf-models-official>=2.5.1\n",
            "  Downloading tf_models_official-2.9.2-py2.py3-none-any.whl (2.1 MB)\n",
            "Collecting tensorflow_io\n",
            "  Downloading tensorflow_io-0.26.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (25.9 MB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.8.0)\n",
            "Collecting pyparsing==2.4.7\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "Collecting py-cpuinfo>=3.3.0\n",
            "  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.0.1)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "Collecting opencv-python-headless\n",
            "  Downloading opencv_python_headless-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (48.3 MB)\n",
            "Collecting tensorflow-text~=2.9.0\n",
            "  Downloading tensorflow_text-2.9.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
            "Collecting pyyaml<6.0,>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.1.0-py3-none-any.whl (92 kB)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n",
            "Collecting tensorflow-model-optimization>=0.4.1\n",
            "  Downloading tensorflow_model_optimization-0.7.2-py2.py3-none-any.whl (237 kB)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n",
            "Collecting tensorflow~=2.9.0\n",
            "  Downloading tensorflow-2.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.21.6)\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.17.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.12.11)\n",
            "Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.31.6)\n",
            "Requirement already satisfied: google-auth<3dev,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.35.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.17.4)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.0.4)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.1)\n",
            "Requirement already satisfied: protobuf<4.0.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.17.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.56.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2022.1)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.23.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (21.3)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.64.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (6.1.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2022.6.15)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.4)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
            "Collecting tensorboard<2.10,>=2.9\n",
            "  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
            "Collecting gast<=0.4.0,>=0.2.1\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Collecting keras\n",
            "  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.46.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.14.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (14.0.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.26.0)\n",
            "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
            "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
            "Collecting flatbuffers<2,>=1.12\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (4.1.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.7)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.8.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.7)\n",
            "Collecting requests<3.0.0dev,>=2.18.0\n",
            "  Downloading requests-2.28.0-py3-none-any.whl (62 kB)\n",
            "Collecting hdfs<3.0.0,>=2.1.0\n",
            "  Downloading hdfs-2.7.0-py3-none-any.whl (34 kB)\n",
            "Collecting cloudpickle<3,>=2.0.0\n",
            "  Downloading cloudpickle-2.1.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
            "Requirement already satisfied: pyarrow<8.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (6.0.1)\n",
            "Collecting proto-plus<2,>=1.7.1\n",
            "  Downloading proto_plus-1.20.6-py3-none-any.whl (46 kB)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
            "Collecting fastavro<2,>=0.23.6\n",
            "  Downloading fastavro-1.5.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "Collecting dill<0.3.2,>=0.3.1.1\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "Collecting orjson<4.0\n",
            "  Downloading orjson-3.7.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (256 kB)\n",
            "Collecting pymongo<4.0.0,>=3.8.0\n",
            "  Downloading pymongo-3.12.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (508 kB)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n",
            "Collecting protobuf<4.0.0dev,>=3.12.0\n",
            "  Downloading protobuf-3.19.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.0.12)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (1.4.3)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.8.9)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.5-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2022.6.2)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (21.4.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.8.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.7.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.16.0)\n",
            "Building wheels for collected packages: object-detection, py-cpuinfo, dill, avro-python3, seqeval\n",
            "  Building wheel for object-detection (setup.py): started\n",
            "  Building wheel for object-detection (setup.py): finished with status 'done'\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1694695 sha256=932c69a1c2e06586c3cac0549d69abe53275feb6de5c3a0d8166e28b914a0865\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-o91dsh41/wheels/fa/a4/d2/e9a5057e414fd46c8e543d2706cd836d64e1fcd9eccceb2329\n",
            "  Building wheel for py-cpuinfo (setup.py): started\n",
            "  Building wheel for py-cpuinfo (setup.py): finished with status 'done'\n",
            "  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22257 sha256=69c2baf0cfdc08a640a82335edb93f2ba4428b1202ae070791cde9181eddfac6\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n",
            "  Building wheel for dill (setup.py): started\n",
            "  Building wheel for dill (setup.py): finished with status 'done'\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78544 sha256=5b26d08773d8ffd5e56fd161c24351cd71687e5ba1a9b98af7344ea371d55cb2\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n",
            "  Building wheel for avro-python3 (setup.py): started\n",
            "  Building wheel for avro-python3 (setup.py): finished with status 'done'\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=44010 sha256=38b49451f3e750b474f0cfbd18505d31f74d40f8adc0f264b300bb786702a7c1\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/e5/b1/6b151d9b535ee50aaa6ab27d145a0104b6df02e5636f0376da\n",
            "  Building wheel for seqeval (setup.py): started\n",
            "  Building wheel for seqeval (setup.py): finished with status 'done'\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=adb93ec697989b167bba8fbb140fda049308e39bea9709d4869ee1024c96f219\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built object-detection py-cpuinfo dill avro-python3 seqeval\n",
            "Installing collected packages: requests, pyparsing, protobuf, tensorflow-estimator, tensorboard, keras, gast, flatbuffers, tensorflow, portalocker, dill, colorama, tf-slim, tensorflow-text, tensorflow-model-optimization, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, pymongo, py-cpuinfo, proto-plus, orjson, opencv-python-headless, hdfs, fastavro, cloudpickle, tf-models-official, tensorflow-io, lvis, avro-python3, apache-beam, object-detection\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.0.9\n",
            "    Uninstalling pyparsing-3.0.9:\n",
            "      Successfully uninstalled pyparsing-3.0.9\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.17.3\n",
            "    Uninstalling protobuf-3.17.3:\n",
            "      Successfully uninstalled protobuf-3.17.3\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 2.0\n",
            "    Uninstalling flatbuffers-2.0:\n",
            "      Successfully uninstalled flatbuffers-2.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.2+zzzcolab20220527125636\n",
            "    Uninstalling tensorflow-2.8.2+zzzcolab20220527125636:\n",
            "      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220527125636\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.5.1\n",
            "    Uninstalling dill-0.3.5.1:\n",
            "      Successfully uninstalled dill-0.3.5.1\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: pymongo\n",
            "    Found existing installation: pymongo 4.1.1\n",
            "    Uninstalling pymongo-4.1.1:\n",
            "      Successfully uninstalled pymongo-4.1.1\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 1.3.0\n",
            "    Uninstalling cloudpickle-1.3.0:\n",
            "      Successfully uninstalled cloudpickle-1.3.0\n",
            "Successfully installed apache-beam-2.39.0 avro-python3-1.10.2 cloudpickle-2.1.0 colorama-0.4.5 dill-0.3.1.1 fastavro-1.5.1 flatbuffers-1.12 gast-0.4.0 hdfs-2.7.0 keras-2.9.0 lvis-0.5.3 object-detection-0.1 opencv-python-headless-4.6.0.66 orjson-3.7.2 portalocker-2.4.0 proto-plus-1.20.6 protobuf-3.19.4 py-cpuinfo-8.0.0 pymongo-3.12.3 pyparsing-2.4.7 pyyaml-5.4.1 requests-2.28.0 sacrebleu-2.1.0 sentencepiece-0.1.96 seqeval-1.2.2 tensorboard-2.9.1 tensorflow-2.9.1 tensorflow-addons-0.17.1 tensorflow-estimator-2.9.0 tensorflow-io-0.26.0 tensorflow-model-optimization-0.7.2 tensorflow-text-2.9.0 tf-models-official-2.9.2 tf-slim-1.1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n",
            "  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\n",
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "multiprocess 0.70.13 requires dill>=0.3.5.1, but you have dill 0.3.1.1 which is incompatible.\n",
            "gym 0.17.3 requires cloudpickle<1.7.0,>=1.2.0, but you have cloudpickle 2.1.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.28.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "sudo apt install -y protobuf-compiler\n",
        "cd models/research/\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "cp object_detection/packages/tf2/setup.py .\n",
        "python -m pip install .\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Resolve OpenCV Conflict"
      ],
      "metadata": {
        "id": "9F5i9jxBmNBy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall opencv-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ew5klayq2O5N",
        "outputId": "c7f28376-4d58-4dcd-e712-4c1467f02ffa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: opencv-python 4.1.2.30\n",
            "Uninstalling opencv-python-4.1.2.30:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/*\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python-4.1.2.30.dist-info/*\n",
            "  Would not remove (might be manually added):\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/config-3.py\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/config.py\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/cv2.abi3.so\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/gapi/__init__.py\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/load_config_py2.py\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/load_config_py3.py\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/mat_wrapper/__init__.py\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/misc/__init__.py\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/misc/version.py\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/utils/__init__.py\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/version.py\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled opencv-python-4.1.2.30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bt6GcRUz2bAy",
        "outputId": "4356e07a-ba21-4405-87c8-3181570a6b9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting opencv-python\n",
            "  Downloading opencv_python-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 60.9 MB 236 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.21.6)\n",
            "Installing collected packages: opencv-python\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed opencv-python-4.6.0.66\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Edit Configuration File\n"
      ],
      "metadata": {
        "id": "4k2Sgs6qmtzc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib.request import ProxyDigestAuthHandler\n",
        "!python /content/drive/MyDrive/uProj1/edit_config.py \\\n",
        "--train_dir /drive/MyDrive/uProj1/data_new/train/ \\\n",
        "--eval_dir /drive/MyDrive/uProj1/data_new/val/ \\\n",
        "--batch_size 2 \\\n",
        "--checkpoint /content/drive/MyDrive/uProj1/experiments/pretrained_model/efficientdet_d1_coco17_tpu-32/checkpoint/ckpt-0 \\\n",
        "--label_map /content/drive/MyDrive/uProj1/experiments/label_map.pbtxt \\\n",
        "--pipeline_config /content/drive/MyDrive/uProj1/ex"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdzuHpNe3U4x",
        "outputId": "43f57831-2b2b-482f-ef52-b758b7b890e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/uProj1/edit_config.py\", line 54, in <module>\n",
            "    args.checkpoint, args.label_map)\n",
            "  File \"/content/drive/MyDrive/uProj1/edit_config.py\", line 21, in edit\n",
            "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/lib/io/file_io.py\", line 114, in read\n",
            "    self._preread_check()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/lib/io/file_io.py\", line 77, in _preread_check\n",
            "    compat.path_to_str(self.__name), 1024 * 512)\n",
            "tensorflow.python.framework.errors_impl.NotFoundError: pipeline.config; No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download Models"
      ],
      "metadata": {
        "id": "7TNXwIA7Au3g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz -P /content/drive/MyDrive/uProj1/experiments/pretrained_model/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctmxKNgi1t-y",
        "outputId": "32ed5b04-5e92-4272-943d-5b8e5c874705"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-22 01:11:40--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 74.125.141.128, 2607:f8b0:400c:c06::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|74.125.141.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 244817203 (233M) [application/x-tar]\n",
            "Saving to: ‘/content/drive/MyDrive/uProj1/experiments/pretrained_model/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz’\n",
            "\n",
            "ssd_resnet50_v1_fpn 100%[===================>] 233.48M  49.7MB/s    in 4.6s    \n",
            "\n",
            "2022-06-22 01:11:45 (50.5 MB/s) - ‘/content/drive/MyDrive/uProj1/experiments/pretrained_model/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz’ saved [244817203/244817203]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xvzf /content/drive/MyDrive/uProj1/experiments/pretrained_model/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz \\\n",
        "-C /content/drive/MyDrive/uProj1/experiments/pretrained_model/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yg5JhW_59wlW",
        "outputId": "4ad101dc-bde1-4cdf-ad5a-232534086197"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/\n",
            "ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint/\n",
            "ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
            "ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint/checkpoint\n",
            "ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0.index\n",
            "ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/pipeline.config\n",
            "ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/saved_model/\n",
            "ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/saved_model/saved_model.pb\n",
            "ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/saved_model/assets/\n",
            "ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/\n",
            "ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
            "ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/variables.index\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xvzf /content/drive/MyDrive/uProj1/experiments/pretrained_model/efficientdet_d1_coco17_tpu-32.tar.gz \\\n",
        "-C /content/drive/MyDrive/uProj1/experiments/pretrained_model/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lcs947b_gNI",
        "outputId": "77524d2e-9422-4fe8-fd79-dc8a3e55bd69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "efficientdet_d1_coco17_tpu-32/\n",
            "efficientdet_d1_coco17_tpu-32/checkpoint/\n",
            "efficientdet_d1_coco17_tpu-32/checkpoint/ckpt-0.data-00000-of-00001\n",
            "efficientdet_d1_coco17_tpu-32/checkpoint/checkpoint\n",
            "efficientdet_d1_coco17_tpu-32/checkpoint/ckpt-0.index\n",
            "efficientdet_d1_coco17_tpu-32/pipeline.config\n",
            "efficientdet_d1_coco17_tpu-32/saved_model/\n",
            "efficientdet_d1_coco17_tpu-32/saved_model/saved_model.pb\n",
            "efficientdet_d1_coco17_tpu-32/saved_model/assets/\n",
            "efficientdet_d1_coco17_tpu-32/saved_model/variables/\n",
            "efficientdet_d1_coco17_tpu-32/saved_model/variables/variables.data-00000-of-00001\n",
            "efficientdet_d1_coco17_tpu-32/saved_model/variables/variables.index\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -R /content/drive/MyDrive/uProj1/experiments/pretrained_model/efficientdet_d1_coco17_tpu-32.tar.gz"
      ],
      "metadata": {
        "id": "mxghlMNNAek8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -R /content/drive/MyDrive/uProj1/experiments/pretrained_model/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz"
      ],
      "metadata": {
        "id": "XvOYbWcgAoM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/uProj1/edit_config.py \\\n",
        "--train_dir /content/drive/MyDrive/uProj1/data_new/train/ \\\n",
        "--eval_dir /content/drive/MyDrive/uProj1/data_new/val/ \\\n",
        "--batch_size 2 \\\n",
        "--checkpoint /content/drive/MyDrive/uProj1/experiments/pretrained_model/efficientdet_d1_coco17_tpu-32/checkpoint/ckpt-0 \\\n",
        "--label_map /content/drive/MyDrive/uProj1/experiments/label_map.pbtxt \\\n",
        "--pipeline_config /content/drive/MyDrive/uProj1/experiments/pretrained_model/efficientdet_d1_coco17_tpu-32/pipeline.config"
      ],
      "metadata": {
        "id": "x7nX7KDa_1k3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv pipeline_new.config /content/drive/MyDrive/uProj1/experiments/reference/"
      ],
      "metadata": {
        "id": "bslPofj0F246"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Model Training"
      ],
      "metadata": {
        "id": "sLnSXADJk2yS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python drive/MyDrive/uProj1/experiments/model_main_tf2.py \\\n",
        "--model_dir=drive/MyDrive/uProj1/experiments/reference/experiments/pretrained_model/efficientdet_d1_coco17_tpu/saved_model  \\\n",
        "--pipeline_config_path=drive/MyDrive/uProj1/experiments/reference/pipeline_new.config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "599AHZq3g4cr",
        "outputId": "a0cd9b82-711b-4cbc-f809-7b14c60d8f2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-22 18:10:25.433335: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2022-06-22 18:10:25.435550: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcupti.so.11.2'; dlerror: libcupti.so.11.2: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.7/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "I0622 18:10:25.682223 140378194028416 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "INFO:tensorflow:Maybe overwriting train_steps: None\n",
            "I0622 18:10:26.690782 140378194028416 config_util.py:552] Maybe overwriting train_steps: None\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0622 18:10:26.690950 140378194028416 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "I0622 18:10:26.697974 140378194028416 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I0622 18:10:26.698083 140378194028416 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 88\n",
            "I0622 18:10:26.698134 140378194028416 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 4\n",
            "I0622 18:10:26.701573 140378194028416 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0622 18:10:26.834296 140378194028416 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0622 18:10:26.836023 140378194028416 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0622 18:10:26.837966 140378194028416 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0622 18:10:26.838778 140378194028416 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0622 18:10:26.849324 140378194028416 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0622 18:10:26.852893 140378194028416 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0622 18:10:26.858158 140378194028416 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0622 18:10:26.858252 140378194028416 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0622 18:10:26.873408 140378194028416 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0622 18:10:26.874297 140378194028416 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0622 18:10:26.875813 140378194028416 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0622 18:10:26.876606 140378194028416 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0622 18:10:27.038119 140378194028416 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0622 18:10:27.038235 140378194028416 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0622 18:10:27.403752 140378194028416 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0622 18:10:27.403919 140378194028416 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0622 18:10:27.748880 140378194028416 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0622 18:10:27.749025 140378194028416 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0622 18:10:28.206716 140378194028416 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0622 18:10:28.206865 140378194028416 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0622 18:10:28.673407 140378194028416 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0622 18:10:28.673550 140378194028416 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0622 18:10:29.249911 140378194028416 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0622 18:10:29.250062 140378194028416 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I0622 18:10:29.485967 140378194028416 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I0622 18:10:29.532907 140378194028416 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "W0622 18:10:29.579636 140378194028416 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/drive/MyDrive/uProj1/data_new/train/training_segment-1005081002024129653_5313_150_5333_150_with_camera_labels.tfrecord', '/content/drive/MyDrive/uProj1/data_new/train/training_segment-10023947602400723454_1120_000_1140_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/uProj1/data_new/train/training_segment-10017090168044687777_6380_000_6400_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/uProj1/data_new/train/training_segment-10094743350625019937_3420_000_3440_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/uProj1/data_new/train/training_segment-10072140764565668044_4060_000_4080_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/uProj1/data_new/train/training_segment-10075870402459732738_1060_000_1080_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/uProj1/data_new/train/training_segment-10096619443888687526_2820_000_2840_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/uProj1/data_new/train/training_segment-10061305430875486848_1080_000_1100_000_with_camera_labels.tfrecord']\n",
            "I0622 18:10:30.127447 140378194028416 dataset_builder.py:162] Reading unweighted datasets: ['/content/drive/MyDrive/uProj1/data_new/train/training_segment-1005081002024129653_5313_150_5333_150_with_camera_labels.tfrecord', '/content/drive/MyDrive/uProj1/data_new/train/training_segment-10023947602400723454_1120_000_1140_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/uProj1/data_new/train/training_segment-10017090168044687777_6380_000_6400_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/uProj1/data_new/train/training_segment-10094743350625019937_3420_000_3440_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/uProj1/data_new/train/training_segment-10072140764565668044_4060_000_4080_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/uProj1/data_new/train/training_segment-10075870402459732738_1060_000_1080_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/uProj1/data_new/train/training_segment-10096619443888687526_2820_000_2840_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/uProj1/data_new/train/training_segment-10061305430875486848_1080_000_1100_000_with_camera_labels.tfrecord']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/drive/MyDrive/uProj1/data_new/train/training_segment-1005081002024129653_5313_150_5333_150_with_camera_labels.tfrecord', '/content/drive/MyDrive/uProj1/data_new/train/training_segment-10023947602400723454_1120_000_1140_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/uProj1/data_new/train/training_segment-10017090168044687777_6380_000_6400_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/uProj1/data_new/train/training_segment-10094743350625019937_3420_000_3440_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/uProj1/data_new/train/training_segment-10072140764565668044_4060_000_4080_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/uProj1/data_new/train/training_segment-10075870402459732738_1060_000_1080_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/uProj1/data_new/train/training_segment-10096619443888687526_2820_000_2840_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/uProj1/data_new/train/training_segment-10061305430875486848_1080_000_1100_000_with_camera_labels.tfrecord']\n",
            "I0622 18:10:30.858998 140378194028416 dataset_builder.py:79] Reading record datasets for input file: ['/content/drive/MyDrive/uProj1/data_new/train/training_segment-1005081002024129653_5313_150_5333_150_with_camera_labels.tfrecord', '/content/drive/MyDrive/uProj1/data_new/train/training_segment-10023947602400723454_1120_000_1140_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/uProj1/data_new/train/training_segment-10017090168044687777_6380_000_6400_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/uProj1/data_new/train/training_segment-10094743350625019937_3420_000_3440_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/uProj1/data_new/train/training_segment-10072140764565668044_4060_000_4080_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/uProj1/data_new/train/training_segment-10075870402459732738_1060_000_1080_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/uProj1/data_new/train/training_segment-10096619443888687526_2820_000_2840_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/uProj1/data_new/train/training_segment-10061305430875486848_1080_000_1100_000_with_camera_labels.tfrecord']\n",
            "INFO:tensorflow:Number of filenames to read: 8\n",
            "I0622 18:10:30.859175 140378194028416 dataset_builder.py:80] Number of filenames to read: 8\n",
            "WARNING:tensorflow:num_readers has been reduced to 8 to match input file shards.\n",
            "W0622 18:10:30.859236 140378194028416 dataset_builder.py:87] num_readers has been reduced to 8 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W0622 18:10:30.861455 140378194028416 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0622 18:10:30.879601 140378194028416 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0622 18:10:37.262237 140378194028416 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0622 18:10:40.994554 140378194028416 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "2022-06-22 18:11:28.463028: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Could not parse example input, value: '\n",
            "�\u0015\n",
            "%1005081002024129653_5313_150_5333_150\u0012�\u0001\b\u0001\u0011�R[�.F�@\u0011�R[�.F�@\u0011�N��Y�@\u0011�G��T�@\u0011\u001e��&\u0002Ӥ?\u0011�/�\u0007h�տ\u0011OC\u0013\u0018��Z?\u0011��ǵ��I�\u0011\n",
            "2022-06-22 18:11:28.495027: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Could not parse example input, value: '\n",
            "�\u0015\n",
            "&10072140764565668044_4060_000_4080_000\u0012�\u0001\b\u0001\u0011(\u0015B]�.�@\u0011(\u0015B]�.�@\u0011\u0013�A_\u000bÍ@\u0011j\u001c\u0007��n�@\u0011�El��ȩ?\u0011\u0001\u000e�jUPֿ\u00118%\u0003цvZ?\u0011&�#�ΘN�\u0011\n",
            "2022-06-22 18:11:28.496476: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Could not parse example input, value: '\n",
            "�\u0015\n",
            "&10096619443888687526_2820_000_2840_000\u0012�\u0001\b\u0001\u0011'��\u0001I\u0018�@\u0011'��\u0001I\u0018�@\u0011t�ɤ�|�@\u0011�\f8�Ӷ�@\u0011�ӑ8\u00124�?\u0011�i���nտ\u0011���s|u@?\u0011�3:!��N�\u0011\n",
            "2022-06-22 18:11:28.499560: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Could not parse example input, value: '\n",
            "�\u0015\n",
            "&10075870402459732738_1060_000_1080_000\u0012�\u0001\b\u0001\u0011w��\u0017S\u0010�@\u0011w��\u0017S\u0010�@\u0011r(a��Ӎ@\u0011`9�1�Ӄ@\u0011\u0005�L����?\u0011Peq��qԿ\u0011\u00145\u0002z5\u001e �\u0011��\u000f�\u001fa�\u0011\n",
            "2022-06-22 18:11:28.553275: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Could not parse example input, value: '\n",
            "�\u0015\n",
            "&10075870402459732738_1060_000_1080_000\u0012�\u0001\b\u0001\u0011w��\u0017S\u0010�@\u0011w��\u0017S\u0010�@\u0011r(a��Ӎ@\u0011`9�1�Ӄ@\u0011\u0005�L����?\u0011Peq��qԿ\u0011\u00145\u0002z5\u001e �\u0011��\u000f�\u001fa�\u0011\n",
            "2022-06-22 18:11:28.622790: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Could not parse example input, value: '\n",
            "�\u0015\n",
            "&10096619443888687526_2820_000_2840_000\u0012�\u0001\b\u0001\u0011'��\u0001I\u0018�@\u0011'��\u0001I\u0018�@\u0011t�ɤ�|�@\u0011�\f8�Ӷ�@\u0011�ӑ8\u00124�?\u0011�i���nտ\u0011���s|u@?\u0011�3:!��N�\u0011\n",
            "2022-06-22 18:11:28.630403: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Could not parse example input, value: '\n",
            "�\u0015\n",
            "&10017090168044687777_6380_000_6400_000\u0012�\u0001\b\u0001\u0011[\t�Y9\u0017�@\u0011[\t�Y9\u0017�@\u0011\u000315*LÍ@\u0011\u0002�<��ԃ@\u0011Sû\n",
            "�&�?\u0011��🸦տ\u0011�\u0016���)�>\u0011��<+@dG?\u0011\n",
            "2022-06-22 18:11:28.662872: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Could not parse example input, value: '\n",
            "�\u0015\n",
            "%1005081002024129653_5313_150_5333_150\u0012�\u0001\b\u0001\u0011�R[�.F�@\u0011�R[�.F�@\u0011�N��Y�@\u0011�G��T�@\u0011\u001e��&\u0002Ӥ?\u0011�/�\u0007h�տ\u0011OC\u0013\u0018��Z?\u0011��ǵ��I�\u0011\n",
            "2022-06-22 18:11:28.689522: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Could not parse example input, value: '\n",
            "�\u0015\n",
            "&10061305430875486848_1080_000_1100_000\u0012�\u0001\b\u0001\u0011V\"\u001d�\b�@\u0011V\"\u001d�\b�@\u0011)t�ߘ��@\u0011`��\u001e�Ƀ@\u0011(�j�٩�?\u0011\u00057�\t�\u001eտ\u0011=�3�5\u000bQ?\u0011�\u0017�K\u0010�Y�\u0011\n",
            "2022-06-22 18:11:28.727564: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Could not parse example input, value: '\n",
            "�\u0015\n",
            "&10017090168044687777_6380_000_6400_000\u0012�\u0001\b\u0001\u0011[\t�Y9\u0017�@\u0011[\t�Y9\u0017�@\u0011\u000315*LÍ@\u0011\u0002�<��ԃ@\u0011Sû\n",
            "�&�?\u0011��🸦տ\u0011�\u0016���)�>\u0011��<+@dG?\u0011\n",
            "2022-06-22 18:11:28.748600: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Could not parse example input, value: '\n",
            "�\u0015\n",
            "&10061305430875486848_1080_000_1100_000\u0012�\u0001\b\u0001\u0011V\"\u001d�\b�@\u0011V\"\u001d�\b�@\u0011)t�ߘ��@\u0011`��\u001e�Ƀ@\u0011(�j�٩�?\u0011\u00057�\t�\u001eտ\u0011=�3�5\u000bQ?\u0011�\u0017�K\u0010�Y�\u0011\n",
            "2022-06-22 18:11:28.755021: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Could not parse example input, value: '\n",
            "�\u0015\n",
            "&10017090168044687777_6380_000_6400_000\u0012�\u0001\b\u0001\u0011[\t�Y9\u0017�@\u0011[\t�Y9\u0017�@\u0011\u000315*LÍ@\u0011\u0002�<��ԃ@\u0011Sû\n",
            "�&�?\u0011��🸦տ\u0011�\u0016���)�>\u0011��<+@dG?\u0011\n",
            "2022-06-22 18:11:28.762189: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Could not parse example input, value: '\n",
            "�\u0015\n",
            "&10096619443888687526_2820_000_2840_000\u0012�\u0001\b\u0001\u0011'��\u0001I\u0018�@\u0011'��\u0001I\u0018�@\u0011t�ɤ�|�@\u0011�\f8�Ӷ�@\u0011�ӑ8\u00124�?\u0011�i���nտ\u0011���s|u@?\u0011�3:!��N�\u0011\n",
            "2022-06-22 18:11:28.847095: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Could not parse example input, value: '\n",
            "�\u0015\n",
            "&10096619443888687526_2820_000_2840_000\u0012�\u0001\b\u0001\u0011'��\u0001I\u0018�@\u0011'��\u0001I\u0018�@\u0011t�ɤ�|�@\u0011�\f8�Ӷ�@\u0011�ӑ8\u00124�?\u0011�i���nտ\u0011���s|u@?\u0011�3:!��N�\u0011\n",
            "Traceback (most recent call last):\n",
            "  File \"drive/MyDrive/uProj1/experiments/model_main_tf2.py\", line 119, in <module>\n",
            "    tf.compat.v1.app.run()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/platform/app.py\", line 36, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 312, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 258, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"drive/MyDrive/uProj1/experiments/model_main_tf2.py\", line 111, in main\n",
            "2022-06-22 18:11:28.910517: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Could not parse example input, value: '\n",
            "�\u0015\n",
            "%1005081002024129653_5313_150_5333_150\u0012�\u0001\b\u0001\u0011�R[�.F�@\u0011�R[�.F�@\u0011�N��Y�@\u0011�G��T�@\u0011\u001e��&\u0002Ӥ?\u0011�/�\u0007h�տ\u0011OC\u0013\u0018��Z?\u0011��ǵ��I�\u0011\n",
            "2022-06-22 18:11:28.915417: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Could not parse example input, value: '\n",
            "�\u0015\n",
            "&10075870402459732738_1060_000_1080_000\u0012�\u0001\b\u0001\u0011w��\u0017S\u0010�@\u0011w��\u0017S\u0010�@\u0011r(a��Ӎ@\u0011`9�1�Ӄ@\u0011\u0005�L����?\u0011Peq��qԿ\u0011\u00145\u0002z5\u001e �\u0011��\u000f�\u001fa�\u0011\n",
            "2022-06-22 18:11:28.928091: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Could not parse example input, value: '\n",
            "�\u0015\n",
            "&10075870402459732738_1060_000_1080_000\u0012�\u0001\b\u0001\u0011w��\u0017S\u0010�@\u0011w��\u0017S\u0010�@\u0011r(a��Ӎ@\u0011`9�1�Ӄ@\u0011\u0005�L����?\u0011Peq��qԿ\u0011\u00145\u0002z5\u001e �\u0011��\u000f�\u001fa�\u0011\n",
            "2022-06-22 18:11:28.930838: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Could not parse example input, value: '\n",
            "�\u0015\n",
            "&10094743350625019937_3420_000_3440_000\u0012�\u0001\b\u0001\u0011'��\u0001I\u0018�@\u0011'��\u0001I\u0018�@\u0011t�ɤ�|�@\u0011�\f8�Ӷ�@\u0011�ӑ8\u00124�?\u0011�i���nտ\u0011���s|u@?\u0011�3:!��N�\u0011\n",
            "2022-06-22 18:11:28.955269: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Could not parse example input, value: '\n",
            "�\u0015\n",
            "&10017090168044687777_6380_000_6400_000\u0012�\u0001\b\u0001\u0011[\t�Y9\u0017�@\u0011[\t�Y9\u0017�@\u0011\u000315*LÍ@\u0011\u0002�<��ԃ@\u0011Sû\n",
            "�&�?\u0011��🸦տ\u0011�\u0016���)�>\u0011��<+@dG?\u0011\n",
            "    record_summaries=FLAGS.record_summaries)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py\", line 609, in train_loop\n",
            "    train_input, unpad_groundtruth_tensors)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py\", line 401, in load_fine_tune_checkpoint\n",
            "    _ensure_model_is_built(model, input_dataset, unpad_groundtruth_tensors)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py\", line 161, in _ensure_model_is_built\n",
            "    features, labels = iter(input_dataset).next()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/input_lib.py\", line 569, in next\n",
            "    return self.__next__()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/input_lib.py\", line 573, in __next__\n",
            "    return self.get_next()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/input_lib.py\", line 630, in get_next\n",
            "    return self._get_next_no_partial_batch_handling(name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/input_lib.py\", line 662, in _get_next_no_partial_batch_handling\n",
            "    replicas.extend(self._iterators[i].get_next_as_list(new_name))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/input_lib.py\", line 1632, in get_next_as_list\n",
            "    return self._format_data_list_with_options(self._iterator.get_next())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py\", line 531, in get_next\n",
            "    result.append(self._device_iterators[i].get_next())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\", line 819, in get_next\n",
            "2022-06-22 18:11:28.999536: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Could not parse example input, value: '\n",
            "�\u0015\n",
            "&10094743350625019937_3420_000_3440_000\u0012�\u0001\b\u0001\u0011'��\u0001I\u0018�@\u0011'��\u0001I\u0018�@\u0011t�ɤ�|�@\u0011�\f8�Ӷ�@\u0011�ӑ8\u00124�?\u0011�i���nտ\u0011���s|u@?\u0011�3:!��N�\u0011\n",
            "    return self._next_internal()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\", line 752, in _next_internal\n",
            "    output_shapes=self._flat_output_shapes)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 3014, in iterator_get_next\n",
            "2022-06-22 18:11:29.004104: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Could not parse example input, value: '\n",
            "�\u0015\n",
            "&10023947602400723454_1120_000_1140_000\u0012�\u0001\b\u0001\u0011'��\u0001I\u0018�@\u0011'��\u0001I\u0018�@\u0011t�ɤ�|�@\u0011�\f8�Ӷ�@\u0011�ӑ8\u00124�?\u0011�i���nտ\u0011���s|u@?\u0011�3:!��N�\u0011\n",
            "    \"output_shapes\", output_shapes)\n",
            "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xa8 in position 40: invalid start byte\n",
            "2022-06-22 18:11:29.014662: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Could not parse example input, value: '\n",
            "�\u0015\n",
            "%1005081002024129653_5313_150_5333_150\u0012�\u0001\b\u0001\u0011�R[�.F�@\u0011�R[�.F�@\u0011�N��Y�@\u0011�G��T�@\u0011\u001e��&\u0002Ӥ?\u0011�/�\u0007h�տ\u0011OC\u0013\u0018��Z?\u0011��ǵ��I�\u0011\n",
            "2022-06-22 18:11:29.041134: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Could not parse example input, value: '\n",
            "�\u0015\n",
            "%1005081002024129653_5313_150_5333_150\u0012�\u0001\b\u0001\u0011�R[�.F�@\u0011�R[�.F�@\u0011�N��Y�@\u0011�G��T�@\u0011\u001e��&\u0002Ӥ?\u0011�/�\u0007h�տ\u0011OC\u0013\u0018��Z?\u0011��ǵ��I�\u0011\n",
            "2022-06-22 18:11:29.059702: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Could not parse example input, value: '\n",
            "�\u0015\n",
            "&10075870402459732738_1060_000_1080_000\u0012�\u0001\b\u0001\u0011w��\u0017S\u0010�@\u0011w��\u0017S\u0010�@\u0011r(a��Ӎ@\u0011`9�1�Ӄ@\u0011\u0005�L����?\u0011Peq��qԿ\u0011\u00145\u0002z5\u001e �\u0011��\u000f�\u001fa�\u0011\n",
            "2022-06-22 18:11:29.082734: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Could not parse example input, value: '\n",
            "�\u0015\n",
            "&10096619443888687526_2820_000_2840_000\u0012�\u0001\b\u0001\u0011'��\u0001I\u0018�@\u0011'��\u0001I\u0018�@\u0011t�ɤ�|�@\u0011�\f8�Ӷ�@\u0011�ӑ8\u00124�?\u0011�i���nտ\u0011���s|u@?\u0011�3:!��N�\u0011\n",
            "2022-06-22 18:11:29.106992: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Could not parse example input, value: '\n",
            "�\u0015\n",
            "&10075870402459732738_1060_000_1080_000\u0012�\u0001\b\u0001\u0011w��\u0017S\u0010�@\u0011w��\u0017S\u0010�@\u0011r(a��Ӎ@\u0011`9�1�Ӄ@\u0011\u0005�L����?\u0011Peq��qԿ\u0011\u00145\u0002z5\u001e �\u0011��\u000f�\u001fa�\u0011\n",
            "2022-06-22 18:11:29.112634: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Could not parse example input, value: '\n",
            "�\u0015\n",
            "&10096619443888687526_2820_000_2840_000\u0012�\u0001\b\u0001\u0011'��\u0001I\u0018�@\u0011'��\u0001I\u0018�@\u0011t�ɤ�|�@\u0011�\f8�Ӷ�@\u0011�ӑ8\u00124�?\u0011�i���nտ\u0011���s|u@?\u0011�3:!��N�\u0011\n",
            "2022-06-22 18:11:29.136954: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Could not parse example input, value: '\n",
            "�\u0015\n",
            "&10096619443888687526_2820_000_2840_000\u0012�\u0001\b\u0001\u0011'��\u0001I\u0018�@\u0011'��\u0001I\u0018�@\u0011t�ɤ�|�@\u0011�\f8�Ӷ�@\u0011�ӑ8\u00124�?\u0011�i���nտ\u0011���s|u@?\u0011�3:!��N�\u0011\n",
            "2022-06-22 18:11:29.146780: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Could not parse example input, value: '\n",
            "�\u0015\n",
            "&10094743350625019937_3420_000_3440_000\u0012�\u0001\b\u0001\u0011'��\u0001I\u0018�@\u0011'��\u0001I\u0018�@\u0011t�ɤ�|�@\u0011�\f8�Ӷ�@\u0011�ӑ8\u00124�?\u0011�i���nտ\u0011���s|u@?\u0011�3:!��N�\u0011\n",
            "2022-06-22 18:11:29.188694: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Could not parse example input, value: '\n",
            "�\u0015\n",
            "&10075870402459732738_1060_000_1080_000\u0012�\u0001\b\u0001\u0011w��\u0017S\u0010�@\u0011w��\u0017S\u0010�@\u0011r(a��Ӎ@\u0011`9�1�Ӄ@\u0011\u0005�L����?\u0011Peq��qԿ\u0011\u00145\u0002z5\u001e �\u0011��\u000f�\u001fa�\u0011\n",
            "2022-06-22 18:11:29.231114: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Could not parse example input, value: '\n",
            "�\u0015\n",
            "&10094743350625019937_3420_000_3440_000\u0012�\u0001\b\u0001\u0011'��\u0001I\u0018�@\u0011'��\u0001I\u0018�@\u0011t�ɤ�|�@\u0011�\f8�Ӷ�@\u0011�ӑ8\u00124�?\u0011�i���nտ\u0011���s|u@?\u0011�3:!��N�\u0011\n",
            "2022-06-22 18:11:29.242930: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Could not parse example input, value: '\n",
            "�\u0015\n",
            "&10023947602400723454_1120_000_1140_000\u0012�\u0001\b\u0001\u0011'��\u0001I\u0018�@\u0011'��\u0001I\u0018�@\u0011t�ɤ�|�@\u0011�\f8�Ӷ�@\u0011�ӑ8\u00124�?\u0011�i���nտ\u0011���s|u@?\u0011�3:!��N�\u0011\n",
            "2022-06-22 18:11:29.253439: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Could not parse example input, value: '\n",
            "�\u0015\n",
            "%1005081002024129653_5313_150_5333_150\u0012�\u0001\b\u0001\u0011�R[�.F�@\u0011�R[�.F�@\u0011�N��Y�@\u0011�G��T�@\u0011\u001e��&\u0002Ӥ?\u0011�/�\u0007h�տ\u0011OC\u0013\u0018��Z?\u0011��ǵ��I�\u0011\n",
            "2022-06-22 18:11:29.268141: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Could not parse example input, value: '\n",
            "�\u0015\n",
            "&10094743350625019937_3420_000_3440_000\u0012�\u0001\b\u0001\u0011'��\u0001I\u0018�@\u0011'��\u0001I\u0018�@\u0011t�ɤ�|�@\u0011�\f8�Ӷ�@\u0011�ӑ8\u00124�?\u0011�i���nտ\u0011���s|u@?\u0011�3:!��N�\u0011\n",
            "2022-06-22 18:11:29.314518: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Could not parse example input, value: '\n",
            "�\u0015\n",
            "&10075870402459732738_1060_000_1080_000\u0012�\u0001\b\u0001\u0011w��\u0017S\u0010�@\u0011w��\u0017S\u0010�@\u0011r(a��Ӎ@\u0011`9�1�Ӄ@\u0011\u0005�L����?\u0011Peq��qԿ\u0011\u00145\u0002z5\u001e �\u0011��\u000f�\u001fa�\u0011\n",
            "2022-06-22 18:11:29.327212: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Could not parse example input, value: '\n",
            "�\u0015\n",
            "&10075870402459732738_1060_000_1080_000\u0012�\u0001\b\u0001\u0011w��\u0017S\u0010�@\u0011w��\u0017S\u0010�@\u0011r(a��Ӎ@\u0011`9�1�Ӄ@\u0011\u0005�L����?\u0011Peq��qԿ\u0011\u00145\u0002z5\u001e �\u0011��\u000f�\u001fa�\u0011\n",
            "2022-06-22 18:11:29.337414: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Could not parse example input, value: '\n",
            "�\u0015\n",
            "&10023947602400723454_1120_000_1140_000\u0012�\u0001\b\u0001\u0011'��\u0001I\u0018�@\u0011'��\u0001I\u0018�@\u0011t�ɤ�|�@\u0011�\f8�Ӷ�@\u0011�ӑ8\u00124�?\u0011�i���nտ\u0011���s|u@?\u0011�3:!��N�\u0011\n",
            "2022-06-22 18:11:29.365955: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Could not parse example input, value: '\n",
            "�\u0015\n",
            "&10023947602400723454_1120_000_1140_000\u0012�\u0001\b\u0001\u0011'��\u0001I\u0018�@\u0011'��\u0001I\u0018�@\u0011t�ɤ�|�@\u0011�\f8�Ӷ�@\u0011�ӑ8\u00124�?\u0011�i���nտ\u0011���s|u@?\u0011�3:!��N�\u0011\n",
            "2022-06-22 18:11:29.371142: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Could not parse example input, value: '\n",
            "�\u0015\n",
            "&10023947602400723454_1120_000_1140_000\u0012�\u0001\b\u0001\u0011'��\u0001I\u0018�@\u0011'��\u0001I\u0018�@\u0011t�ɤ�|�@\u0011�\f8�Ӷ�@\u0011�ӑ8\u00124�?\u0011�i���nտ\u0011���s|u@?\u0011�3:!��N�\u0011\n",
            "2022-06-22 18:11:29.395718: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Could not parse example input, value: '\n",
            "�\u0015\n",
            "&10075870402459732738_1060_000_1080_000\u0012�\u0001\b\u0001\u0011w��\u0017S\u0010�@\u0011w��\u0017S\u0010�@\u0011r(a��Ӎ@\u0011`9�1�Ӄ@\u0011\u0005�L����?\u0011Peq��qԿ\u0011\u00145\u0002z5\u001e �\u0011��\u000f�\u001fa�\u0011\n",
            "2022-06-22 18:11:29.407355: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Could not parse example input, value: '\n",
            "�\u0015\n",
            "&10094743350625019937_3420_000_3440_000\u0012�\u0001\b\u0001\u0011'��\u0001I\u0018�@\u0011'��\u0001I\u0018�@\u0011t�ɤ�|�@\u0011�\f8�Ӷ�@\u0011�ӑ8\u00124�?\u0011�i���nտ\u0011���s|u@?\u0011�3:!��N�\u0011\n",
            "2022-06-22 18:11:29.421721: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Could not parse example input, value: '\n",
            "�\u0015\n",
            "&10075870402459732738_1060_000_1080_000\u0012�\u0001\b\u0001\u0011w��\u0017S\u0010�@\u0011w��\u0017S\u0010�@\u0011r(a��Ӎ@\u0011`9�1�Ӄ@\u0011\u0005�L����?\u0011Peq��qԿ\u0011\u00145\u0002z5\u001e �\u0011��\u000f�\u001fa�\u0011\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "72JSQXKAHNRn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}